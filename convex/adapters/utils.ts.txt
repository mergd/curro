"use node";

import { CheerioCrawler } from "crawlee";

interface CrawleeResult {
  html: string;
  url: string;
  success: boolean;
  error?: string;
}

/**
 * Enhanced scraping using Crawlee for JavaScript-heavy sites
 * Fallback when simple fetch + JSDOM isn't sufficient
 */
export async function crawlWithCrawlee(
  url: string,
  options: {
    waitForSelector?: string;
    timeout?: number;
    maxRetries?: number;
  } = {},
): Promise<CrawleeResult> {
  const { waitForSelector, timeout = 30000, maxRetries = 2 } = options;

  let result: CrawleeResult = {
    html: "",
    url,
    success: false,
    error: "Not attempted",
  };

  try {
    console.log(`Using Crawlee to scrape: ${url}`);

    const crawler = new CheerioCrawler({
      maxRequestRetries: maxRetries,
      requestHandlerTimeoutSecs: timeout / 1000,
      maxRequestsPerCrawl: 1,

      async requestHandler({ $, request, body }) {
        console.log(`Crawlee processing: ${request.url}`);

        // Wait for specific selector if provided
        if (waitForSelector) {
          // For Cheerio, we just check if the selector exists
          const element = $(waitForSelector);
          if (element.length === 0) {
            console.warn(`Selector ${waitForSelector} not found`);
          } else {
            console.log(`Found selector ${waitForSelector}`);
          }
        }

        result = {
          html: body.toString(),
          url: request.url,
          success: true,
        };
      },

      failedRequestHandler({ request, error }) {
        const errorMessage =
          error instanceof Error ? error.message : String(error);
        console.error(`Crawlee failed for ${request.url}:`, errorMessage);
        result = {
          html: "",
          url: request.url,
          success: false,
          error: errorMessage,
        };
      },
    });

    await crawler.run([url]);

    return result;
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error(`Crawlee error for ${url}:`, errorMessage);

    return {
      html: "",
      url,
      success: false,
      error: errorMessage,
    };
  }
}

/**
 * Smart fetch that tries simple fetch first, then falls back to Crawlee if needed
 */
export async function smartFetch(
  url: string,
  options: {
    useragent?: string;
    timeout?: number;
    fallbackToCrawlee?: boolean;
    crawleeOptions?: {
      waitForSelector?: string;
      timeout?: number;
      maxRetries?: number;
    };
  } = {},
): Promise<{
  html: string;
  success: boolean;
  method: "fetch" | "crawlee";
  error?: string;
}> {
  const {
    useragent = "Mozilla/5.0 (compatible; JobScraper/1.0)",
    timeout = 10000,
    fallbackToCrawlee = false,
    crawleeOptions = {},
  } = options;

  // Try simple fetch first
  try {
    console.log(`Trying simple fetch for: ${url}`);

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), timeout);

    const response = await fetch(url, {
      headers: { "User-Agent": useragent },
      signal: controller.signal,
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    const html = await response.text();

    // Simple heuristic: if HTML is very small, it might be a SPA that needs JS rendering
    if (html.length < 1000 && fallbackToCrawlee) {
      console.log(`HTML too small (${html.length} chars), trying Crawlee...`);
      const crawleeResult = await crawlWithCrawlee(url, crawleeOptions);

      if (crawleeResult.success) {
        return {
          html: crawleeResult.html,
          success: true,
          method: "crawlee",
        };
      }
    }

    return {
      html,
      success: true,
      method: "fetch",
    };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.warn(`Simple fetch failed for ${url}: ${errorMessage}`);

    if (fallbackToCrawlee) {
      console.log(`Falling back to Crawlee for: ${url}`);
      const crawleeResult = await crawlWithCrawlee(url, crawleeOptions);

      return {
        html: crawleeResult.html,
        success: crawleeResult.success,
        method: "crawlee",
        error: crawleeResult.success ? undefined : crawleeResult.error,
      };
    }

    return {
      html: "",
      success: false,
      method: "fetch",
      error: errorMessage,
    };
  }
}
